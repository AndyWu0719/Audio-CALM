defaults:
  - _self_

hydra:
  run:
    dir: .
  output_subdir: null
  job:
    chdir: False

model:
  head_type: "flow"
  tts_loss_weight: 0.0
  asr_loss_weight: 1.0
  len_pred_loss_weight: 0.1       # TTS len_loss 不参与，但留值无碍
  dur_pred_loss_weight: 0.0       # 本阶段不训 dur

  qwen_path: "${hydra:runtime.cwd}/qwen2_1.5B_Instruct"
  vae_path: "${hydra:runtime.cwd}/outputs/checkpoints/vae_4x_128_5e-4/checkpoint-17350"

  use_lora: True
  lora_rank: 64
  lora_alpha: 128
  lora_dropout: 0.05
  merge_lora: False

  freeze_projector: True           # ASR 阶段建议冻结 projector，减少干扰
  use_precomputed_latents: True
  latent_dim: 128

  tts_flow_hidden_dim: 768
  tts_flow_num_layers: 4
  asr_flow_hidden_dim: 768
  asr_flow_num_layers: 4

  pretrained_projector_path: "${hydra:runtime.cwd}/outputs/checkpoints/omni_flow_tts/best/input_proj.bin"
  pretrained_tts_head_path: "${hydra:runtime.cwd}/outputs/checkpoints/omni_flow_tts/best/tts_flow_head.bin"
  pretrained_tts_len_pred_path: "${hydra:runtime.cwd}/outputs/checkpoints/omni_flow_tts/best/tts_len_predictor.bin"
  pretrained_asr_head_path: null
  pretrained_asr_query_path: null
  pretrained_lora_path: "${hydra:runtime.cwd}/outputs/checkpoints/omni_flow_tts/best/adapter_model.bin"  # 若 TTS 用了 LoRA，填此；否则设 null

  mel_mean: -6.589515
  mel_std: 3.860679

data:
  task_mode: "asr"
  task_prob_tts: 0.0

  datasets:
    asr:
      latent_dir: "${hydra:runtime.cwd}/data/latents/train/LibriSpeech"
      eval_latent_dir: "${hydra:runtime.cwd}/data/latents/dev/LibriSpeech"
      subsets: "train-clean-100,train-clean-360,train-other-500"
    tts:
      latent_dir: "${hydra:runtime.cwd}/data/latents/train/LibriTTS_R"
      eval_latent_dir: "${hydra:runtime.cwd}/data/latents/dev/LibriTTS_R"
      subsets: "train-clean-100,train-clean-360,train-other-500"

  train_subsets: "train-clean-100,train-clean-360,train-other-500"
  eval_subsets: "dev-clean"
  max_text_len: 96
  max_audio_len: 384
  latent_downsample: 1

training:
  output_dir: "${hydra:runtime.cwd}/outputs/checkpoints/omni_flow_asr"
  run_name: "omni-flow-asr"

  resume_from_checkpoint: null
  ignore_data_skip: False

  per_device_train_batch_size: 16
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 2

  soa_lr_mult: 5.0
  proj_lr_mult: 1.0          # projector 冻结时无效
  head_lr_mult: 3.0

  learning_rate: 5e-5
  num_train_epochs: 5        # 视收敛可调

  bf16: True
  gradient_checkpointing: True

  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.1
  max_grad_norm: 1.0

  logging_steps: 10
  save_strategy: "steps"
  save_steps: 1000
  save_total_limit: 2

  eval_strategy: "steps"
  eval_steps: 1000
  load_best_model_at_end: True
  metric_for_best_model: "loss"

  group_by_length: False
  label_smoothing_factor: 0.0
  ddp_find_unused_parameters: True
  dataloader_num_workers: 5
  dataloader_pin_memory: True
  remove_unused_columns: False
  report_to: "wandb"
  seed: 42
  deepspeed: "${hydra:runtime.cwd}/train/ds_config.json"

evaluation:
  task: "asr"
  datasets:
    asr:
      latent_dir: "${hydra:runtime.cwd}/data/latents/dev/LibriSpeech"
      subsets: "dev-clean"
    tts:
      latent_dir: "${hydra:runtime.cwd}/data/latents/dev/LibriTTS_R"
      subsets: "dev-clean"
  checkpoint_path: "${hydra:runtime.cwd}/outputs/checkpoints/omni_flow_asr/best"
  output_dir: "${hydra:runtime.cwd}/outputs/eval_results_asr"
  max_samples: 50
  use_vocoder: True
  steps: 20
  cfg_scale: 3.0
  eval_asr_model: "openai/whisper-tiny.en"
  wandb_project: "Omni-Flow-Eval"
  wandb_entity: null
  web_demo: False
  seed: 42