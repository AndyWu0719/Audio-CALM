# config/calm_config.yaml
# Omni-Flow Hydra 配置文件
# 统一管理 Omni-Flow 双向流匹配模型的超参数

defaults:
  - _self_

hydra:
  run:
    dir: .
  output_subdir: null
  job:
    chdir: False

# -------------------------------------------------------------------
# MODEL CONFIGURATION (模型参数配置)
# -------------------------------------------------------------------
model:
  # 生成头类型
  head_type: "flow"
  
  # 损失函数权重
  tts_loss_weight: 1.0
  asr_loss_weight: 1.0
  len_pred_loss_weight: 0.1
  dur_pred_loss_weight: 0.05

  # === 基础模型路径 ===
  # Qwen2 LLM 的路径
  qwen_path: "${hydra:runtime.cwd}/qwen2_1.5B_Instruct"
  
  # VAE 的路径 (用于音频压缩和解压)
  vae_path: "${hydra:runtime.cwd}/outputs/checkpoints/vae_4x_128_5e-4/checkpoint-17350"
  
  # === LoRA 配置 (Unified) ===
  use_lora: True
  lora_rank: 64
  lora_alpha: 128
  lora_dropout: 0.05
  merge_lora: False
  
  # === 冻结策略 ===
  # Omni-Flow 建议解冻 Projector 以便学习 Audio -> Text 的语义映射
  freeze_projector: False
  
  # === Latent 配置 ===
  use_precomputed_latents: True
  latent_dim: 128

  tts_flow_hidden_dim: 768 
  tts_flow_num_layers: 4

  asr_flow_hidden_dim: 768
  asr_flow_num_layers: 4

  # === 软重启 (Soft Restart) ===
  pretrained_projector_path: null
  pretrained_tts_head_path: null
  pretrained_asr_head_path: null
  pretrained_lora_path: null

  mel_mean: -6.589515 # 预计算 Mel 归一化参数，需要自行计算
  mel_std: 3.860679  # 预计算 Mel 归一化参数，需要自行计算


# -------------------------------------------------------------------
# DATA CONFIGURATION (数据参数配置)
# -------------------------------------------------------------------
data:
  # === 任务模式 ===
  # "tts", "asr", "mix"
  task_mode: "mix" 
  task_prob_tts: 0.5

  # === 数据集路径 ===
  datasets:
    asr:
      latent_dir: "${hydra:runtime.cwd}/data/latents/train/LibriSpeech"
      eval_latent_dir: "${hydra:runtime.cwd}/data/latents/dev/LibriSpeech"
      subsets: "train-clean-100,train-clean-360,train-other-500" 
      
    tts:
      latent_dir: "${hydra:runtime.cwd}/data/latents/train/LibriTTS_R"
      eval_latent_dir: "${hydra:runtime.cwd}/data/latents/dev/LibriTTS_R"
      subsets: "train-clean-100,train-clean-360,train-other-500"
      
  train_subsets: "train-clean-100,train-clean-360,train-other-500"
  eval_subsets: "dev-clean"
  
  # === 序列约束 ===
  max_text_len: 96
  max_audio_len: 384
  latent_downsample: 1

# -------------------------------------------------------------------
# TRAINING CONFIGURATION (训练参数配置)
# -------------------------------------------------------------------
training:
  output_dir: "${hydra:runtime.cwd}/outputs/checkpoints/omni_flow"
  run_name: "omni-flow"
  
  resume_from_checkpoint: null 
  ignore_data_skip: False
  
  # === Batch设置 ===
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 2

  soa_lr_mult: 5.0
  proj_lr_mult: 1.0
  head_lr_mult: 3.0
  
  # === 优化器设置 ===
  learning_rate: 5e-5
  num_train_epochs: 8
  
  # === 硬件加速 ===
  bf16: True
  gradient_checkpointing: True
  
  # === 调度器 ===
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.1
  max_grad_norm: 1.0
  
  # === 日志与保存 ===
  logging_steps: 10
  save_strategy: "steps"
  save_steps: 500
  save_total_limit: 2
  
  # === 评估策略 ===
  eval_strategy: "steps"
  eval_steps: 500
  load_best_model_at_end: True
  metric_for_best_model: "loss"
  
  # === 其他 ===
  group_by_length: False
  label_smoothing_factor: 0.0
  ddp_find_unused_parameters: True
  dataloader_num_workers: 5
  dataloader_pin_memory: True
  remove_unused_columns: False
  report_to: "wandb"
  seed: 42
  deepspeed: "${hydra:runtime.cwd}/train/ds_config.json"

# -------------------------------------------------------------------
# EVALUATION CONFIGURATION (评估参数配置)
# -------------------------------------------------------------------
evaluation:
  # 评估任务类型: "tts", "asr", "mix"
  task: "mix"
  datasets:
    asr:
      latent_dir: "${hydra:runtime.cwd}/data/latents/dev/LibriSpeech"
      subsets: "dev-clean"
    
    tts:
      latent_dir: "${hydra:runtime.cwd}/data/latents/dev/LibriTTS_R"
      subsets: "dev-clean"
  
  # === 推理 Checkpoint ===
  checkpoint_path: "${hydra:runtime.cwd}/outputs/checkpoints/omni_flow/4-128-5e-5-2048-6/checkpoint-7350"
  output_dir: "${hydra:runtime.cwd}/outputs/eval_results"
  
  # === 生成参数 ===
  max_samples: 50
  use_vocoder: True
  steps: 20
  cfg_scale: 3.0
  
  # === ASR 评估 ===
  eval_asr_model: "openai/whisper-tiny.en"
  
  # === 追踪 ===
  wandb_project: "Omni-Flow-Eval"
  wandb_entity: null
  web_demo: False
  seed: 42