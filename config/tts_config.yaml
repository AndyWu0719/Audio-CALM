# config/tts_config.yaml
# 专用于 TTS (Text-to-Speech) 任务的训练配置

defaults:
  - _self_

hydra:
  run:
    dir: .
  output_subdir: null
  job:
    chdir: False

# -------------------------------------------------------------------
# MODEL CONFIGURATION (模型参数)
# -------------------------------------------------------------------
model:
  head_type: "flow"
  audio_loss_weight: 1.0
  ctc_loss_weight: 0.1

  # === 基础模型路径 ===
  qwen_path: "${hydra:runtime.cwd}/qwen2_7B_Instruct"
  vae_path: "${hydra:runtime.cwd}/outputs/checkpoints/vae_4x_64_5e-4/checkpoint-8700"
  
  # === LoRA 配置 ===
  use_lora: True
  lora_rank: 64
  lora_alpha: 128
  lora_dropout: 0.05
  merge_lora: False
  
  # === [关键] 冻结策略 ===
  # TTS 训练时通常冻结 Projector，直接使用 ASR 训练好的特征提取能力
  freeze_projector: False
  
  # === Latent 配置 ===
  use_precomputed_latents: True
  latent_dim: 64

  # === Flow Head 配置 ===
  flow_hidden_dim: 2048 
  flow_num_layers: 6 

  # === [关键] 软重启 (Soft Restart) ===
  # 【重要】这里必须填入你 ASR 训练产出的 input_proj.bin 路径！
  # 示例路径，请替换为你的实际路径：
  pretrained_projector_path: "/data0/determined/users/andywu/Audio-CALM-v2/outputs/checkpoints/calm_moa_flow/asr-4-64-1e-4-2048-6/input_proj.bin"
  pretrained_head_path: null
  
  # MoA Adapter 路径
  pretrained_lora_path_tts: null
  pretrained_lora_path_asr: null

# -------------------------------------------------------------------
# DATA CONFIGURATION (数据参数)
# -------------------------------------------------------------------
data:
  # === [关键] 任务模式 ===
  task_mode: "tts"
  task_prob_tts: 1.0

  # 数据集路径
  datasets:
    tts:
      raw_root: "${hydra:runtime.cwd}/data/raw/LibriTTS_R/train"
      latent_dir: "${hydra:runtime.cwd}/data/latents/train/LibriTTS_R"
      eval_latent_dir: "${hydra:runtime.cwd}/data/latents/dev/LibriTTS_R"
    
    # 占位符
    asr:
      raw_root: null
      latent_dir: null
      eval_latent_dir: null
    mix:
      raw_root: null
      latent_dir: null
      eval_latent_dir: null

  # 子数据集名称
  train_subsets: "train-clean-100,train-clean-360,train-other-500"
  eval_subsets: "dev-clean"
  
  # 序列约束
  max_text_len: 128
  max_audio_len: 512
  latent_downsample: 4

# -------------------------------------------------------------------
# TRAINING CONFIGURATION (训练参数)
# -------------------------------------------------------------------
training:
  output_dir: "${hydra:runtime.cwd}/outputs/checkpoints/calm_moa/tts"
  run_name: "tts-4x-64-1e-4-2048-6"
  
  resume_from_checkpoint: null 
  ignore_data_skip: False
  
  # Batch 设置
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 4 
  
  # 优化器
  learning_rate: 1e-4
  num_train_epochs: 3

  # SOA Token: 冷启动需要大倍率 (10.0 ~ 50.0)
  soa_lr_mult: 10.0  
  
  # Projector: 微调时使用较小倍率
  projector_lr_mult: 0.1 
  
  # Flow Head: 始终从头练，保持标准倍率
  head_lr_mult: 1.0
  
  # 硬件加速
  bf16: True
  gradient_checkpointing: True
  
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.05
  max_grad_norm: 1.0
  
  # 日志与保存
  logging_steps: 10
  save_strategy: "steps"
  save_steps: 500
  save_total_limit: 2
  
  # 评估
  eval_strategy: "steps"
  eval_steps: 500
  load_best_model_at_end: True
  metric_for_best_model: "loss"
  
  # 其他
  group_by_length: False
  label_smoothing_factor: 0.0
  ddp_find_unused_parameters: True
  dataloader_num_workers: 8
  dataloader_pin_memory: True
  remove_unused_columns: False
  report_to: "wandb"
  seed: 42
  deepspeed: "${hydra:runtime.cwd}/train/ds_config.json"

# -------------------------------------------------------------------
# EVALUATION CONFIGURATION (评估参数)
# -------------------------------------------------------------------
evaluation:
  task: "tts"
  test_file: "${hydra:runtime.cwd}/data/jsonl/dev.jsonl"
  
  # 推理用 Checkpoint (训练后填写)
  checkpoint_path: null
  output_dir: "${hydra:runtime.cwd}/outputs/eval_results/tts"
  
  max_samples: 50
  max_latents: 300
  use_vocoder: True
  flow_steps: 50
  cfg_scale: 1.0
  eval_asr_model: "openai/whisper-tiny.en"
  
  wandb_project: "Audio-CALM-Eval"
  wandb_entity: null
  web_demo: False
  seed: 42