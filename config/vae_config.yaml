defaults:
  - _self_

hydra:
  run:
    dir: .
  output_subdir: null
  job:
    chdir: False

model:
  hidden_channels: 512
  latent_channels: 64
  strides: [2]
  kl_weight: 0.0001
  kl_clamp: 2.0
  latent_dropout: 0.0
  norm_num_groups: 32

data:
  data_dir: "${hydra:runtime.cwd}/data/raw/LibriTTS_R/train"
  eval_data_dir: "${hydra:runtime.cwd}/data/raw/LibriTTS_R/dev-clean"
  train_subsets: "train-clean-100,train-clean-360,train-other-500"
  eval_subsets: "dev-clean"
  crop_size: 512

training:
  output_dir: "${hydra:runtime.cwd}/outputs/checkpoints/audio_vae_2x_kl_annealing_l1_ssim"
  per_device_train_batch_size: 512
  per_device_eval_batch_size: 512
  gradient_accumulation_steps: 1
  learning_rate: 5e-4
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.05
  num_train_epochs: 50
  save_steps: 2000
  save_total_limit: 3
  logging_steps: 50
  eval_strategy: "steps"
  eval_steps: 2000
  load_best_model_at_end: True
  metric_for_best_model: "loss"
  remove_unused_columns: False
  dataloader_num_workers: 8
  bf16: True
  ddp_find_unused_parameters: False
  report_to: "wandb"
  run_name: "audio_vae_2x_kl_annealing_l1_ssim"
  save_strategy: "steps"
  seed: 42