# preprocess/build_manifest.py
import os
import glob
import json
import argparse
from tqdm import tqdm

def main():
    """
    åŠŸèƒ½ï¼šç”Ÿæˆç”¨äºè®­ç»ƒçš„ JSONL æ¸…å•æ–‡ä»¶ã€‚
    
    ã€æ–‡ä»¶é—´å…³ç³»ã€‘ï¼š
    - è¾“å…¥ä¾èµ–ï¼šä¾èµ– `process_dataset.py` ç”Ÿæˆçš„ç›®å½•ç»“æ„ï¼ˆåŒ…å« .trans.txt å’Œ .pt æ–‡ä»¶ï¼‰ã€‚
    - è¾“å‡ºæµå‘ï¼šç”Ÿæˆçš„ .jsonl æ–‡ä»¶å°†è¢« `train_calm.py` ä¸­çš„ `CalmDataset` ç±»è¯»å–ã€‚
    """
    parser = argparse.ArgumentParser()
    parser.add_argument("--latent_dir", type=str, required=True, help="å¤„ç†å¥½çš„æ½œå˜é‡æ ¹ç›®å½•")
    parser.add_argument("--output_file", type=str, required=True, help="è¾“å‡ºçš„ .jsonl è·¯å¾„")
    args = parser.parse_args()

    print(f"ğŸ”¨ æ­£åœ¨ä» {args.latent_dir} æ„å»ºæ¸…å•...")
    
    # 1. æŸ¥æ‰¾æ‰€æœ‰çš„è½¬å½•æ–‡ä»¶
    # è¿™äº› .trans.txt æ–‡ä»¶æ˜¯ç”± `process_dataset.py` åœ¨å¤„ç†éŸ³é¢‘æ—¶ç”Ÿæˆæˆ–å¤åˆ¶çš„ã€‚
    # å®ƒä»¬åŒ…å«äº†æ–‡ä»¶å ID å’Œå¯¹åº”çš„æ–‡æœ¬å†…å®¹ã€‚
    trans_files = glob.glob(os.path.join(args.latent_dir, "**", "*.trans.txt"), recursive=True)
    
    entries = []
    for trans_path in tqdm(trans_files):
        folder = os.path.dirname(trans_path)
        with open(trans_path, 'r', encoding='utf-8') as f:
            for line in f:
                # 2. è§£ææ¯ä¸€è¡Œè½¬å½•æ–‡æœ¬
                # é¢„æœŸæ ¼å¼: "æ–‡ä»¶ID æ–‡æœ¬å†…å®¹"
                parts = line.strip().split(" ", 1)
                if len(parts) != 2: continue
                
                file_id, text = parts
                
                # 3. å®šä½å¯¹åº”çš„æ½œå˜é‡æ–‡ä»¶ (.pt)
                # ã€å¯¹åº”å…³ç³»ã€‘ï¼šè¿™é‡ŒåŒ¹é… `process_dataset.py` ä¸­çš„ä¿å­˜å‘½åè§„åˆ™ï¼š
                # save_path = os.path.join(save_dir, f"{file_id}.pt")
                latent_path = os.path.join(folder, f"{file_id}.pt")
                
                # 4. éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§å¹¶æ·»åŠ åˆ°åˆ—è¡¨
                if os.path.exists(latent_path):
                    # åˆ›å»ºç¬¦åˆ CalmDataset.__getitem__ è¯»å–æ ¼å¼çš„æ¡ç›®
                    entries.append({
                        "id": file_id,
                        "audio": latent_path, # è®­ç»ƒæ—¶å°†é€šè¿‡ torch.load() åŠ è½½æ­¤è·¯å¾„
                        "text": text,
                        # "dataset": "libritts" # å¯é€‰å…ƒæ•°æ®
                    })

    # 5. å°†ç»“æœå†™å…¥ JSONL æ–‡ä»¶
    print(f"ğŸ“ æ­£åœ¨å†™å…¥ {len(entries)} æ¡æ•°æ®åˆ° {args.output_file}...")
    with open(args.output_file, 'w', encoding='utf-8') as f:
        for entry in entries:
            f.write(json.dumps(entry) + "\n")
            
    print("âœ… æ¸…å•ç”Ÿæˆå®Œæˆã€‚")

if __name__ == "__main__":
    main()