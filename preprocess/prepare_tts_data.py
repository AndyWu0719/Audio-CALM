import os
import glob
import argparse
import torch
import torch.nn as nn
import torchaudio
from tqdm import tqdm
import sys
import math

# === å¼•å…¥ä½ çš„ VAE æ¨¡å‹ ===
sys.path.append(os.getcwd()) 
from models.modeling_vae import AcousticVAE 

# ==============================================================================
# 1. å¤ç”¨ä½ ä¹‹å‰çš„ MelExtractor é…ç½®
# ==============================================================================
SAMPLE_RATE = 16000
N_MELS = 80
N_FFT = 1024
HOP_LENGTH = 256 

class MelExtractor(nn.Module):
    def __init__(self):
        super().__init__()
        self.mel_transform = torchaudio.transforms.MelSpectrogram(
            sample_rate=SAMPLE_RATE,
            n_fft=N_FFT,
            hop_length=HOP_LENGTH,
            n_mels=N_MELS,
            power=2.0,
            normalized=False,
            f_min=0,
            f_max=8000,
            norm="slaney",
            mel_scale="slaney"
        )
    
    def forward(self, wav):
        # wav: [B, T] or [1, T]
        mel = self.mel_transform(wav)
        # Log-Mel Scaling (å’Œä½ è®­ç»ƒ VAE æ—¶ä¿æŒä¸€è‡´)
        mel = torch.log(torch.clamp(mel, min=1e-5))
        return mel

# ==============================================================================
# 2. VAE åŠ è½½ä¸å¤„ç†é€»è¾‘
# ==============================================================================
def load_vae(ckpt_path, device):
    print(f"ğŸ”„ Loading VAE from: {ckpt_path}")
    try:
        # å°è¯•æ ‡å‡†åŠ è½½
        vae = AcousticVAE.from_pretrained(ckpt_path)
    except Exception as e:
        print(f"âš ï¸ Standard load failed: {e}. Trying state_dict load...")
        # å¦‚æœä½ å­˜çš„æ˜¯æ•´ä¸ªå¯¹è±¡æˆ–è€…åªæ˜¯æƒé‡ï¼Œè¿™é‡Œæä¾›ä¸€ä¸ª fallback
        # å‡è®¾ä½ æœ‰ä¸€ä¸ª config.json åœ¨åŒç›®å½•ä¸‹ï¼Œæˆ–è€…ç¡¬ç¼–ç  Config
        from models.modeling_vae import AudioVAEConfig
        config = AudioVAEConfig() # ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œæˆ–è€…ä½ éœ€è¦æ ¹æ®ä½ çš„è®­ç»ƒä¿®æ”¹å‚æ•°
        vae = AcousticVAE(config)
        
        # å°è¯•åŠ è½½æƒé‡ (å¦‚æœæ˜¯ .bin æˆ– .pt)
        if os.path.isdir(ckpt_path):
            ckpt_file = os.path.join(ckpt_path, "pytorch_model.bin")
        else:
            ckpt_file = ckpt_path
            
        state_dict = torch.load(ckpt_file, map_location='cpu')
        vae.load_state_dict(state_dict, strict=False)

    vae.to(device)
    vae.eval()
    return vae

def process_file(vae, mel_extractor, wav_path, out_root, in_root, device):
    try:
        # 1. è·¯å¾„è®¡ç®—
        rel_path = os.path.relpath(os.path.dirname(wav_path), in_root)
        save_dir = os.path.join(out_root, rel_path)
        os.makedirs(save_dir, exist_ok=True)

        file_id = os.path.splitext(os.path.basename(wav_path))[0]
        save_path = os.path.join(save_dir, f"{file_id}.pt")
        
        if os.path.exists(save_path):
            return None, None

        # 2. åŠ è½½éŸ³é¢‘
        wav, sr = torchaudio.load(wav_path)
        
        # è½¬å•å£°é“
        if wav.shape[0] > 1:
            wav = wav.mean(dim=0, keepdim=True)
        
        # é‡é‡‡æ ·
        if sr != SAMPLE_RATE:
            resampler = torchaudio.transforms.Resample(sr, SAMPLE_RATE)
            wav = resampler(wav)

        # 3. [å…³é”®] æ³¢å½¢å½’ä¸€åŒ– (å¤ç”¨ä½ ä¹‹å‰çš„é€»è¾‘)
        # wav = wav / (torch.max(torch.abs(wav)) + 1e-8) * 0.95
        peak = torch.max(torch.abs(wav))
        if peak > 0:
            wav = wav / (peak + 1e-8) * 0.95

        wav = wav.to(device) # [1, T]

        # 4. æå– Mel é¢‘è°±
        with torch.no_grad():
            mel = mel_extractor(wav) # è¾“å‡º [1, 80, T_mel]
            
            # 5. VAE Encode
            # VAE encode é€šå¸¸è¿”å› (mu, logvar) æˆ– dist
            # ä½ çš„ä»£ç : mu, logvar = self.encode(mel_padded)
            # æˆ‘ä»¬åªéœ€è¦ mu (Latent)
            
            # ä½ çš„ VAE å¯èƒ½éœ€è¦ pad åˆ° stride çš„å€æ•°ï¼Œè¿™é‡Œç®€å•å¤„ç†ä¸€ä¸‹
            # å¦‚æœä½ çš„ VAE forward é‡Œæœ‰ pad é€»è¾‘ï¼Œè¿™é‡Œç›´æ¥è°ƒ encode å¯èƒ½ä¼šæŠ¥é”™å°ºå¯¸ä¸åŒ¹é…
            # ä¸ºäº†å®‰å…¨ï¼Œæˆ‘ä»¬æ‰‹åŠ¨ Pad ä¸€ä¸‹ (å‡è®¾ total_stride æ˜¯ 4 æˆ– 8)
            pad_to = 4 
            if mel.shape[-1] % pad_to != 0:
                pad_len = pad_to - (mel.shape[-1] % pad_to)
                mel = torch.nn.functional.pad(mel, (0, pad_len), mode='reflect')

            mu, _ = vae.encode(mel)
            latent = mu # [1, D, T_latent]

        # [1, D, T] -> [D, T] (64, T)
        latent = latent.squeeze(0).cpu()

        # 6. ä¿å­˜
        torch.save(latent, save_path)

        # 7. å¤„ç†æ–‡æœ¬
        txt_path = wav_path.replace(".wav", ".normalized.txt")
        if os.path.exists(txt_path):
            with open(txt_path, 'r', encoding='utf-8') as f:
                text = f.read().strip()
            trans_file = os.path.join(save_dir, f"{os.path.basename(save_dir)}.trans.txt")
            return trans_file, f"{file_id} {text}"
            
    except Exception as e:
        print(f"\nâŒ Error processing {wav_path}: {e}")
        return None, None
    
    return None, None

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--in_dir", type=str, required=True, help="Input root (e.g. LibriTTS_R/train-clean-100)")
    parser.add_argument("--out_dir", type=str, required=True, help="Output root")
    parser.add_argument("--vae_ckpt", type=str, required=True, help="VAE checkpoint path")
    args = parser.parse_args()

    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸš€ Using device: {device}")

    # åˆå§‹åŒ–æ¨¡å‹
    vae = load_vae(args.vae_ckpt, device)
    mel_extractor = MelExtractor().to(device)
    mel_extractor.eval()

    # æ‰«ææ–‡ä»¶
    print(f"ğŸ” Scanning .wav files in {args.in_dir}...")
    wav_files = glob.glob(os.path.join(args.in_dir, "**", "*.wav"), recursive=True)
    print(f"ğŸ“‚ Found {len(wav_files)} files.")

    # å¤„ç†å¾ªç¯
    trans_buffer = {} 

    for wav_path in tqdm(wav_files):
        trans_file, line = process_file(vae, mel_extractor, wav_path, args.out_dir, args.in_dir, device)
        if trans_file and line:
            if trans_file not in trans_buffer:
                trans_buffer[trans_file] = []
            trans_buffer[trans_file].append(line)

    # å†™å…¥ trans.txt
    print("ğŸ“ Writing transcription files...")
    for path, lines in trans_buffer.items():
        with open(path, 'w', encoding='utf-8') as f:
            for line in lines:
                f.write(line + "\n")

    print(f"âœ… Done! Latents saved to {args.out_dir}")

if __name__ == "__main__":
    main()