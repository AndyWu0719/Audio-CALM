import os
import glob
import argparse
import torch
import torch.nn as nn
import torchaudio
import torch.multiprocessing as mp
from tqdm import tqdm
import sys
import math

# === å¼•å…¥ä½ çš„ VAE æ¨¡å‹ ===
sys.path.append(os.getcwd()) 
from models.modeling_vae import AcousticVAE 

# ==============================================================================
# 1. ä½ çš„ MelExtractor (å®Œå…¨ä¿ç•™å‚æ•°)
# ==============================================================================
SAMPLE_RATE = 16000
N_MELS = 80
N_FFT = 1024
HOP_LENGTH = 256 

class MelExtractor(nn.Module):
    def __init__(self):
        super().__init__()
        self.mel_transform = torchaudio.transforms.MelSpectrogram(
            sample_rate=SAMPLE_RATE,
            n_fft=N_FFT,
            hop_length=HOP_LENGTH,
            n_mels=N_MELS,
            power=2.0,
            normalized=False, # ä½ ä¹‹å‰çš„è®¾ç½®
            f_min=0,
            f_max=8000,
            norm="slaney",
            mel_scale="slaney"
        )
    
    def forward(self, wav):
        # wav: [1, T]
        mel = self.mel_transform(wav)
        mel = torch.log(torch.clamp(mel, min=1e-5))
        return mel

# ==============================================================================
# 2. æ ¸å¿ƒå¤„ç†é€»è¾‘ (Latent + Text)
# ==============================================================================
def process_chunk(rank, gpu_id, file_list, args):
    device = torch.device(f"cuda:{gpu_id}")
    
    # åˆå§‹åŒ–ç»„ä»¶
    try:
        # åŠ è½½ VAE
        vae = AcousticVAE.from_pretrained(args.vae_ckpt).to(device)
        vae.eval()
        # åŠ è½½ Mel æå–å™¨
        mel_extractor = MelExtractor().to(device)
    except Exception as e:
        print(f"[GPU {gpu_id}] Failed to load models: {e}")
        return

    # è¿›åº¦æ¡
    iterator = tqdm(file_list, desc=f"GPU {gpu_id}", position=rank) if rank < 8 else file_list
    
    # ç”¨äºç¼“å­˜ text å†™å…¥ï¼Œé¿å…é¢‘ç¹ IO
    # Key: trans.txt çš„ç»å¯¹è·¯å¾„, Value: list of lines
    trans_buffer = {} 

    for wav_path in iterator:
        try:
            # --- A. è·¯å¾„è®¡ç®— ---
            # ä¿æŒç›®å½•ç»“æ„: output_dir/subset/reader/chapter/xxx.pt
            rel_path = os.path.relpath(os.path.dirname(wav_path), args.in_dir)
            save_dir = os.path.join(args.out_dir, rel_path)
            
            file_id = os.path.splitext(os.path.basename(wav_path))[0]
            save_path = os.path.join(save_dir, f"{file_id}.pt")
            
            # å¦‚æœå·²å­˜åœ¨ï¼Œè·³è¿‡ Latent è®¡ç®—ï¼Œä½†ä¸èƒ½è·³è¿‡æ–‡æœ¬æ”¶é›†ï¼
            # ä¸ºäº†ç®€å•ï¼Œè¿™é‡Œå»ºè®®å…¨é‡è·‘ã€‚å¦‚æœå¿…é¡»æ–­ç‚¹ç»­ä¼ ï¼Œéœ€è¦é¢å¤–é€»è¾‘å¤„ç†æ–‡æœ¬ã€‚
            if os.path.exists(save_path) and not args.force_overwrite:
                pass 
            else:
                os.makedirs(save_dir, exist_ok=True)

                # --- B. éŸ³é¢‘å¤„ç† (å®Œå…¨å¤ç”¨ä½ çš„é€»è¾‘) ---
                wav, sr = torchaudio.load(wav_path)
                
                # é‡é‡‡æ ·
                if sr != SAMPLE_RATE:
                    resampler = torchaudio.transforms.Resample(sr, SAMPLE_RATE)
                    wav = resampler(wav)

                # è½¬å•å£°é“
                if wav.shape[0] > 1:
                    wav = torch.mean(wav, dim=0, keepdim=True)
                
                # [å…³é”®] ä½ çš„å½’ä¸€åŒ–é€»è¾‘
                peak = torch.max(torch.abs(wav))
                if peak > 0:
                    wav = wav / (peak + 1e-8) * 0.95

                wav = wav.to(device) # [1, T]

                # Mel + VAE
                with torch.no_grad():
                    mel = mel_extractor(wav) # [1, 80, T_mel]
                    
                    # ç®€å•çš„ Pad é€»è¾‘é˜²æ­¢ VAE å°ºå¯¸æŠ¥é”™
                    pad_to = 4
                    if mel.shape[-1] % pad_to != 0:
                        pad_len = pad_to - (mel.shape[-1] % pad_to)
                        mel = torch.nn.functional.pad(mel, (0, pad_len), mode='reflect')

                    # Encode
                    mu, logvar = vae.encode(mel)
                    
                    # ä½ åå¥½ä¿å­˜ mu
                    latent = mu.squeeze(0).cpu() # [64, T_lat]

                # --- C. ä¿å­˜ Latent (å¤ç”¨ä½ çš„ Dict æ ¼å¼) ---
                payload = {
                    "latent": latent,
                    "latent_type": "mu",
                    "vae_path": args.vae_ckpt,
                    # å¯ä»¥é¡ºä¾¿æŠŠ mel å­˜è¿›å»ï¼Œå¦‚æœç¡¬ç›˜å¤Ÿå¤§çš„è¯ï¼Œæ–¹ä¾¿ debug
                    # "mel": mel.squeeze(0).cpu() 
                }
                torch.save(payload, save_path)

            # --- D. [å…³é”®æ–°å¢] æ–‡æœ¬å¤„ç† ---
            # è¯»å–åŒç›®å½•ä¸‹çš„ .normalized.txt
            txt_src = wav_path.replace(".wav", ".normalized.txt")
            if os.path.exists(txt_src):
                with open(txt_src, 'r', encoding='utf-8') as f:
                    text_content = f.read().strip()
                
                # ç¡®å®š trans.txt çš„ä½ç½® (LibriSpeech æ ¼å¼: chapterç›®å½•ä¸‹çš„ trans.txt)
                trans_file_path = os.path.join(save_dir, f"{os.path.basename(save_dir)}.trans.txt")
                
                if trans_file_path not in trans_buffer:
                    trans_buffer[trans_file_path] = []
                
                # æ ¼å¼: ID TEXT
                trans_buffer[trans_file_path].append(f"{file_id} {text_content}")

        except Exception as e:
            print(f"[GPU {gpu_id}] Error: {wav_path} - {e}")

    # --- E. æ‰¹é‡å†™å…¥æ–‡æœ¬ ---
    for trans_path, lines in trans_buffer.items():
        # è¿½åŠ æ¨¡å¼ï¼Œé˜²æ­¢å¤šè¿›ç¨‹è¦†ç›–ï¼ˆè™½ç„¶ç†è®ºä¸Šä¸åŒè¿›ç¨‹å¤„ç†ä¸åŒæ–‡ä»¶ï¼Œä½†åŒä¸€ç›®å½•å¯èƒ½è¢«åˆ†åˆ°ä¸åŒ chunk? 
        # æœ€å¥½æ˜¯æŒ‰ç›®å½•åˆ† chunkï¼Œä½†ä¸ºäº†ç®€å•ï¼Œè¿™é‡Œç”¨è¿½åŠ æ¨¡å¼ + é”ç¨å¾®ä¸å®‰å…¨ä½†é€šå¸¸æ²¡äº‹ï¼Œ
        # æˆ–è€…ç›´æ¥è¦†ç›–ï¼Œå› ä¸ºä¸åŒ chunk ä¸ä¼šé‡å æ–‡ä»¶ï¼‰
        # ç¨³å¦¥èµ·è§ï¼š
        mode = 'a' if os.path.exists(trans_path) else 'w'
        with open(trans_path, mode, encoding='utf-8') as f:
            for line in lines:
                f.write(line + "\n")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--in_dir", type=str, required=True, help="Raw LibriTTS-R root")
    parser.add_argument("--out_dir", type=str, required=True, help="Output root")
    parser.add_argument("--vae_ckpt", type=str, required=True, help="VAE checkpoint path")
    parser.add_argument("--num_gpus", type=int, default=torch.cuda.device_count())
    parser.add_argument("--workers_per_gpu", type=int, default=2)
    parser.add_argument("--force_overwrite", action="store_true")
    args = parser.parse_args()

    print(f"ğŸš€ Scanning wav files in {args.in_dir}...")
    # é€’å½’æŸ¥æ‰¾æ‰€æœ‰ wav
    wav_files = glob.glob(os.path.join(args.in_dir, "**", "*.wav"), recursive=True)
    total_files = len(wav_files)
    print(f"ğŸ“‚ Found {total_files} files.")

    if total_files == 0:
        return

    # å¤šè¿›ç¨‹åˆ†é…
    num_procs = args.num_gpus * args.workers_per_gpu
    chunk_size = math.ceil(total_files / num_procs)
    file_chunks = [wav_files[i:i + chunk_size] for i in range(0, total_files, chunk_size)]

    print(f"ğŸ”¥ Starting {num_procs} processes on {args.num_gpus} GPUs...")
    
    mp.set_start_method('spawn', force=True)
    processes = []
    
    for rank in range(len(file_chunks)):
        gpu_id = rank % args.num_gpus
        p = mp.Process(
            target=process_chunk,
            args=(rank, gpu_id, file_chunks[rank], args)
        )
        p.start()
        processes.append(p)
    
    for p in processes:
        p.join()
        
    print("âœ… All done! Latents and transcripts are ready.")

if __name__ == "__main__":
    main()