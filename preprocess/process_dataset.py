# preprocess/process_dataset.py
import sys
import time
import os
import argparse
import math
import csv
import warnings
import logging
import multiprocessing as mp

# [ä¼˜åŒ–] 1. å¯åŠ¨å³æ‰“å° PIDï¼Œæ–¹ä¾¿ç¡®è®¤è¿›ç¨‹å­˜æ´»
print(f"[Process] Initializing... (PID: {os.getpid()})", flush=True)

import torch
import torchaudio

# [é…ç½®] è·¯å¾„ä¿®å¤ï¼šç¡®ä¿èƒ½å¯¼å…¥é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„æ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path: sys.path.insert(0, project_root)
if current_dir not in sys.path: sys.path.insert(0, current_dir)

# ã€å¯¹åº”å…³ç³»ã€‘ï¼šä» core.py å¯¼å…¥æ ¸å¿ƒå¤„ç†å·¥å…·
from core import MelExtractor, load_vae, process_audio_chunk

# [é…ç½®] å±è”½è­¦å‘Š
warnings.filterwarnings("ignore")
logging.getLogger("torchvision").setLevel(logging.ERROR)

def get_common_voice_map(tsv_path):
    """
    åŠŸèƒ½ï¼šè¯»å– CommonVoice çš„å…ƒæ•°æ®æ–‡ä»¶ (.tsv)ï¼Œå»ºç«‹ æ–‡ä»¶å->æ–‡æœ¬ çš„æ˜ å°„ã€‚
    """
    mapping = {}
    if not os.path.exists(tsv_path): return mapping
    with open(tsv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f, delimiter='\t')
        for row in reader:
            mapping[row['path']] = row['sentence']
    return mapping

def _get_librispeech_text(wav_path):
    """
    åŠŸèƒ½ï¼šè§£æ LibriSpeech æ•°æ®é›†ç›®å½•ä¸‹çš„ .trans.txt æ–‡ä»¶è·å–æ–‡æœ¬ã€‚
    """
    folder = os.path.dirname(wav_path)
    file_id = os.path.splitext(os.path.basename(wav_path))[0]
    try:
        files = os.listdir(folder)
        trans_file = next((f for f in files if f.endswith(".trans.txt")), None)
        if trans_file:
            with open(os.path.join(folder, trans_file), 'r', encoding='utf-8') as f:
                for line in f:
                    if line.startswith(file_id):
                        return line.strip().split(" ", 1)[1]
    except: pass
    return None

def scan_files(root_dir):
    """
    åŠŸèƒ½ï¼šé€’å½’æ‰«æç›®å½•ä¸‹çš„æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶ã€‚
    """
    sys.stdout.write(f"ğŸ” Scanning files in {root_dir} ... ")
    sys.stdout.flush()
    files = []
    extensions = {'.wav', '.flac', '.mp3'}
    for root, _, filenames in os.walk(root_dir):
        for f in filenames:
            if os.path.splitext(f)[1].lower() in extensions:
                files.append(os.path.join(root, f))
    print(f"Found {len(files)} files.", flush=True)
    return files

def worker_process(rank, gpu_id, file_list, args, cv_mapping, queue):
    """
    åŠŸèƒ½ï¼šå•ä¸ªå·¥ä½œè¿›ç¨‹çš„ä¸»é€»è¾‘ã€‚è´Ÿè´£åŠ è½½æ¨¡å‹å¹¶å¤„ç†åˆ†é…ç»™å®ƒçš„æ–‡ä»¶åˆ—è¡¨ã€‚
    
    å‚æ•°ï¼š
    - rank: è¿›ç¨‹ç¼–å·
    - gpu_id: æŒ‡å®šä½¿ç”¨çš„ GPU ID
    - file_list: è¯¥è¿›ç¨‹éœ€è¦å¤„ç†çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    - queue: ç”¨äºå‘ä¸»è¿›ç¨‹æ±‡æŠ¥è¿›åº¦çš„é˜Ÿåˆ—
    """
    # [å…³é”®ä¼˜åŒ–] 1. é™åˆ¶å•æ ¸ï¼Œé˜²æ­¢ CPU äº‰æŠ¢ (å› ä¸º PyTorch å¤šè¿›ç¨‹ä¸‹é»˜è®¤ä¼šäº‰æŠ¢ CPU)
    torch.set_num_threads(1)
    
    try:
        # 1. åŠ è½½æ¨¡å‹åˆ°æŒ‡å®š GPU
        device = torch.device(f"cuda:{gpu_id}")
        # æ ¹æ®æ¨¡å¼å†³å®šæ˜¯å¦åŠ è½½ VAE
        if not args.mel_only:
            vae = load_vae(args.vae_ckpt, device)
            vae.eval()
        # ã€å¯¹åº”å…³ç³»ã€‘ï¼šè°ƒç”¨ core.MelExtractor åˆå§‹åŒ–ç‰¹å¾æå–å™¨
        mel_extractor = MelExtractor().to(device)
        mel_extractor.eval()
    except Exception:
        queue.put(None)
        return

    trans_buffer = {}
    # [å…³é”®ä¼˜åŒ–] 2. æ‰¹é‡æ±‡æŠ¥é˜ˆå€¼ï¼šæ¯å¤„ç† 100 ä¸ªæ–‡ä»¶å‘ä¸»è¿›ç¨‹æ±‡æŠ¥ä¸€æ¬¡ï¼Œå‡å°‘ IPC å¼€é”€
    REPORT_BATCH = 100 
    processed_count = 0

    # [å…³é”®ä¼˜åŒ–] 3. ä½¿ç”¨ inference_mode åŠ é€Ÿå¹¶ç¦ç”¨æ¢¯åº¦è®¡ç®—
    with torch.inference_mode():
        for wav_path in file_list:
            try:
                # --- 2. è·¯å¾„è®¡ç®— ---
                # ç¡®å®šè¾“å‡ºæ–‡ä»¶çš„ä¿å­˜è·¯å¾„
                if args.dataset_name == "commonvoice":
                    file_id = os.path.splitext(os.path.basename(wav_path))[0]
                    save_dir = args.out_dir
                else:
                    # ä¿æŒåŸå§‹ç›®å½•ç»“æ„
                    rel_path = os.path.relpath(os.path.dirname(wav_path), args.in_dir)
                    save_dir = os.path.join(args.out_dir, rel_path)
                    file_id = os.path.splitext(os.path.basename(wav_path))[0]

                save_path = os.path.join(save_dir, f"{file_id}.pt")
                
                # --- 3. è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶ ---
                if os.path.exists(save_path) and not args.force:
                    processed_count += 1
                    if processed_count >= REPORT_BATCH:
                        queue.put(processed_count)
                        processed_count = 0
                    continue

                os.makedirs(save_dir, exist_ok=True)

                # --- 4. éŸ³é¢‘åŠ è½½ä¸æ ‡å‡†åŒ– ---
                wav, sr = torchaudio.load(wav_path)
                if sr != 16000:
                    wav = torchaudio.transforms.Resample(sr, 16000)(wav)
                # ã€å¯¹åº”å…³ç³»ã€‘ï¼šè°ƒç”¨ core.process_audio_chunk è¿›è¡Œå½’ä¸€åŒ–
                # non_blocking=True å°è¯•åŠ é€Ÿ CPU->GPU æ•°æ®ä¼ è¾“
                wav = process_audio_chunk(wav).to(device, non_blocking=True)

                # --- 5. ç‰¹å¾æå–ä¸ç¼–ç  ---
                # æå– Log-Mel
                mel = mel_extractor(wav)
                
                # å¤„ç† VAE çš„ä¸‹é‡‡æ ·å¡«å……é—®é¢˜ (padding)
                pad_to = 4 # VAE é€šå¸¸ä¸‹é‡‡æ · 4 å€ï¼Œæ‰€ä»¥é•¿åº¦è¦æ˜¯ 4 çš„å€æ•°
                if mel.shape[-1] % pad_to != 0:
                    pad_len = pad_to - (mel.shape[-1] % pad_to)
                    mel = torch.nn.functional.pad(mel, (0, pad_len), mode='reflect')
                    
                if args.mel_only:
                    # === åˆ†æ”¯ A: ä»…ä¿å­˜ Mel (ç”¨äºè®­ç»ƒ VAE) ===
                    # å¿…é¡»ä¿å­˜ä¸º "mel" keyï¼Œä»¥ä¾¿ train_vae.py è¯†åˆ«
                    payload = {"mel": mel.squeeze(0).cpu()} 
                    torch.save(payload, save_path)
                else:
                    # === åˆ†æ”¯ B: ä¿å­˜ Latent (ç”¨äºè®­ç»ƒ CALM) ===
                    # å¿…é¡»æœ‰ VAE æ‰èƒ½è¿è¡Œ
                    with torch.no_grad():
                        mu, _ = vae.encode(mel)
                        latent = mu.squeeze(0).cpu() # [Dim, Time]
                    payload = {
                        "latent": latent, 
                        "vae_path": args.vae_ckpt,
                        # "mel": mel.squeeze(0).cpu() # å¯é€‰ï¼šå¦‚æœç¡¬ç›˜ç©ºé—´å¤Ÿï¼Œå»ºè®®åŠ ä¸Š
                    }
                    torch.save(payload, save_path)

                # --- 7. å¤„ç†æ–‡æœ¬ (Transcript) ---
                # æ ¹æ®ä¸åŒæ•°æ®é›†ç±»å‹è·å–æ–‡æœ¬
                text = None
                if args.dataset_name == "libritts":
                    txt_path = wav_path.replace(".wav", ".normalized.txt")
                    if os.path.exists(txt_path):
                        with open(txt_path, 'r', encoding='utf-8') as f: text = f.read().strip()
                elif args.dataset_name == "librispeech":
                    text = _get_librispeech_text(wav_path)
                elif args.dataset_name == "commonvoice":
                    text = cv_mapping.get(os.path.basename(wav_path), None)

                # ç¼“å­˜æ–‡æœ¬ï¼Œç¨åæ‰¹é‡å†™å…¥ .trans.txt
                if text:
                    fname = f"{os.path.basename(save_dir)}.trans.txt"
                    if args.dataset_name == "commonvoice": fname = "commonvoice.trans.txt"
                    tpath = os.path.join(save_dir, fname)
                    if tpath not in trans_buffer: trans_buffer[tpath] = []
                    # æ ¼å¼: file_id text
                    trans_buffer[tpath].append(f"{file_id} {text}")
                
                # è¿›åº¦æ›´æ–°
                processed_count += 1
                if processed_count >= REPORT_BATCH:
                    queue.put(processed_count)
                    processed_count = 0

            except Exception:
                # å‡ºé”™ä¹Ÿè®¡æ•°ï¼Œé˜²æ­¢è¿›åº¦æ¡å¡æ­»ï¼Œä½†é€šå¸¸åº”è®°å½•é”™è¯¯æ—¥å¿—
                processed_count += 1
                if processed_count >= REPORT_BATCH:
                    queue.put(processed_count)
                    processed_count = 0

    # å¾ªç¯ç»“æŸåï¼Œæ±‡æŠ¥å‰©ä½™è¿›åº¦
    if processed_count > 0:
        queue.put(processed_count)

    # 8. å†™å…¥æ–‡æœ¬æ–‡ä»¶ç¼“å­˜
    for path, lines in trans_buffer.items():
        try:
            with open(path, 'a', encoding='utf-8') as f:
                for line in lines: f.write(line + "\n")
        except: pass
    
    # å‘é€ç»“æŸä¿¡å·
    queue.put(None)

def print_progress_bar(iteration, total, prefix='', suffix='', decimals=1, length=50, fill='â–ˆ'):
    """
    åŠŸèƒ½ï¼šåœ¨ç»ˆç«¯æ‰“å°è¿›åº¦æ¡ã€‚
    """
    percent = ("{0:." + str(decimals) + "f}").format(100 * (iteration / float(total)))
    filledLength = int(length * iteration // total)
    bar = fill * filledLength + '-' * (length - filledLength)
    sys.stdout.write(f'\r{prefix} |{bar}| {percent}% {suffix}')
    sys.stdout.flush()

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset_name", type=str, required=True, help="æ•°æ®é›†åç§° (libritts, librispeech, commonvoice)")
    parser.add_argument("--in_dir", type=str, required=True, help="åŸå§‹éŸ³é¢‘è¾“å…¥ç›®å½•")
    parser.add_argument("--out_dir", type=str, required=True, help="Latent è¾“å‡ºç›®å½•")
    parser.add_argument("--vae_ckpt", type=str, default=None, help="VAE æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ (mel_onlyæ¨¡å¼ä¸‹å¯å¿½ç•¥)")
    parser.add_argument("--mel_only", action="store_true", help="ä»…æå– Mel é¢‘è°±(ç”¨äºè®­ç»ƒ VAE), ä¸éœ€è¦åŠ è½½ VAE æ¨¡å‹")
    parser.add_argument("--cv_tsv", type=str, default=None, help="CommonVoice çš„ TSV å…ƒæ•°æ®è·¯å¾„")
    parser.add_argument("--num_gpus", type=int, default=torch.cuda.device_count(), help="ä½¿ç”¨çš„ GPU æ•°é‡")
    parser.add_argument("--workers_per_gpu", type=int, default=4, help="æ¯ä¸ª GPU å¯åŠ¨çš„è¿›ç¨‹æ•°")
    parser.add_argument("--force", action="store_true", help="æ˜¯å¦å¼ºåˆ¶è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶")
    args = parser.parse_args()
    
    if not args.mel_only and args.vae_ckpt is None:
        print("âŒ Error: æå– Latent (é --mel_only æ¨¡å¼) å¿…é¡»æŒ‡å®š --vae_ckpt")
        return

    # 1. æ‰«ææ–‡ä»¶
    files = scan_files(args.in_dir)
    total_files = len(files)
    if total_files == 0: return

    # 2. å‡†å¤‡å…ƒæ•°æ® (ä»…é’ˆå¯¹ CommonVoice)
    cv_mapping = {}
    if args.dataset_name == "commonvoice" and args.cv_tsv:
        print("ğŸ“– Loading CV metadata...", flush=True)
        cv_mapping = get_common_voice_map(args.cv_tsv)

    # 3. ä»»åŠ¡åˆ†ç‰‡ (Sharding)
    num_procs = args.num_gpus * args.workers_per_gpu
    chunk_size = math.ceil(total_files / num_procs)
    chunks = [files[i:i + chunk_size] for i in range(0, total_files, chunk_size)]
    
    # 4. åˆå§‹åŒ–å¤šè¿›ç¨‹ç®¡ç†å™¨
    manager = mp.Manager()
    queue = manager.Queue()
    
    print(f"ğŸ”¥ Launching {len(chunks)} workers...", flush=True)
    
    mp.set_start_method('spawn', force=True)
    processes = []
    active_workers = 0
    
    # 5. å¯åŠ¨å·¥ä½œè¿›ç¨‹
    for rank, chunk in enumerate(chunks):
        if len(chunk) == 0: continue
        gpu_id = rank % args.num_gpus
        p = mp.Process(target=worker_process, args=(rank, gpu_id, chunk, args, cv_mapping, queue))
        p.start()
        processes.append(p)
        active_workers += 1

    # 6. ç›‘æ§è¿›åº¦
    processed_total = 0
    finished_workers = 0
    subset_name = os.path.basename(args.in_dir.rstrip('/'))
    if subset_name == "clips": subset_name = "CV_Full"
    
    print_progress_bar(0, total_files, prefix=f'Processing {subset_name}', length=40)

    start_time = time.time()
    
    # è¿›åº¦æ¡å¾ªç¯ï¼šç›´åˆ°æ‰€æœ‰ worker å‘é€ç»“æŸä¿¡å· (None)
    while finished_workers < active_workers:
        try:
            msg = queue.get(timeout=0.5)
            if msg is None:
                finished_workers += 1
            elif isinstance(msg, int):
                processed_total += msg
                elapsed = time.time() - start_time
                speed = processed_total / (elapsed + 1e-5)
                suffix = f"({processed_total}/{total_files}) [{speed:.1f} file/s]"
                print_progress_bar(processed_total, total_files, prefix=f'Processing {subset_name}', suffix=suffix, length=40)
        except:
            if not any(p.is_alive() for p in processes) and queue.empty():
                break
            continue

    print_progress_bar(total_files, total_files, prefix=f'Processing {subset_name}', suffix='Done!          ', length=40)
    print()
    
    for p in processes: p.join()

if __name__ == "__main__":
    main()