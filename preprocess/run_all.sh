#!/bin/bash

# ==============================================================================
# 0. CONFIGURATION (ÂÖ®Â±ÄÈÖçÁΩÆ)
# ==============================================================================
BASE_DIR="/data0/determined/users/andywu/Audio-CALM-v2"
DATA_ROOT="$BASE_DIR/data"
RAW_ROOT="$DATA_ROOT/raw"
LATENT_ROOT="$DATA_ROOT/latents"
JSONL_ROOT="$DATA_ROOT/jsonl"

PYTHON_BIN="/data0/determined/users/andywu/config/.conda/envs/qwen2_CALM/bin/python"
if [ ! -f "$PYTHON_BIN" ]; then PYTHON_BIN="python"; fi

VAE_CKPT="$BASE_DIR/outputs/checkpoints/audio_vae_4x_kl_annealing_l1_ssim/checkpoint-6900"

export CUDA_VISIBLE_DEVICES=0,1,2,3

# === Ê†∏ÂøÉÂºÄÂÖ≥ ===
DO_PIPELINE=true   # ‰∏ãËΩΩ + Â§ÑÁêÜ
DO_JSONL=true      # ÁîüÊàêÁ¥¢Âºï

# === Êï∞ÊçÆÈõÜÈÄâÊã© ===
DATASETS_TO_RUN=(
    "librispeech"  # ASR
    "libritts"     # TTS
    "commonvoice"  # CV
)

# === Common Voice Credentials ===
CV_API_KEY="30deea4ea405c99c58e9dfac3d94243934ec5c26dfa510451003763f6978482b" 
CV_DOWNLOAD_TOKEN="dlt_f64dba7f-5087-4125-83ce-001365c6b59b" 

# ==============================================================================
# Â∑•ÂÖ∑ÂáΩÊï∞
# ==============================================================================
contains_element() {
  local e match="$1"; shift
  for e; do [[ "$e" == "$match" ]] && return 0; done
  return 1
}

fast_download() {
    local url="$1"
    local filename="$2"
    if command -v aria2c &> /dev/null; then
        echo "üöÄ [Aria2] Downloading $filename..."
        aria2c -x 16 -s 16 -c -o "$filename" "$url"
    else
        echo "üê¢ [Wget] Downloading $filename..."
        wget -c -O "$filename" "$url"
    fi
}

# [Ê†∏ÂøÉÂçáÁ∫ß] ÊûÅÈÄüÊ£ÄÊü•ÈÄªËæë
check_latents_exist() {
    local target_dir="$1"
    
    # 1. ÊúÄÂø´Ê£ÄÊü•ÔºöÁúãÊúâÊ≤°Êúâ .done Ê†áËÆ∞Êñá‰ª∂
    if [ -f "$target_dir/.done" ]; then
        return 0 # Â≠òÂú®‰∏îÂ∑≤ÂÆåÊàê
    fi

    # 2. ÂÖúÂ∫ïÊ£ÄÊü•ÔºöÁúãÊúâÊ≤°Êúâ .pt Êñá‰ª∂ (Èò≤Ê≠¢ÊâãÂä®Âà†‰∫Ü .done ‰ΩÜÊï∞ÊçÆËøòÂú®)
    if [ -d "$target_dir" ]; then
        # find -quit: ÊâæÂà∞Á¨¨‰∏Ä‰∏™Â∞±ÈÄÄÂá∫ÔºåÊûÅÂ§ßÂä†ÈÄü
        if [ -n "$(find "$target_dir" -name "*.pt" -print -quit)" ]; then
            # ÊèêÁ§∫Áî®Êà∑Êï∞ÊçÆÂ≠òÂú®‰ΩÜÊ≤° .done
            # echo "   (Found .pt files but no .done marker. Will attempt resume.)"
            return 1 # ËøîÂõû False ËÆ© Python ËÑöÊú¨ÂéªÊñ≠ÁÇπÁª≠‰º†ÔºåÂπ∂Âú®ÂÆåÊàêÂêéÁîüÊàê .done
        fi
    fi
    return 1 # ‰∏çÂ≠òÂú®
}

# ==============================================================================
# Êï∞ÊçÆÈõÜÂ§ÑÁêÜÂáΩÊï∞
# ==============================================================================

# --- LibriSpeech ---
run_librispeech() {
    echo "========================================================"
    echo "üü¢ [LibriSpeech] Checking Pipeline..."
    echo "========================================================"
    
    declare -A SUBSETS=(
        ["train-clean-100"]=1 ["train-clean-360"]=1 ["train-other-500"]=1
        ["dev-clean"]=1 ["test-clean"]=1
    )
    declare -A SPLIT_MAP=(
        ["train-clean-100"]="train" ["train-clean-360"]="train" ["train-other-500"]="train"
        ["dev-clean"]="dev" ["test-clean"]="test"
    )
    BASE_URL="https://www.openslr.org/resources/12"
    WORK_DIR="$RAW_ROOT/LibriSpeech"
    mkdir -p "$WORK_DIR"; cd "$WORK_DIR" || return

    for subset in "${!SUBSETS[@]}"; do
        split=${SPLIT_MAP[$subset]}
        OUT_DIR="$LATENT_ROOT/$split/LibriSpeech/$subset"

        # [Âä†ÈÄü] Ê£ÄÊü•ÊòØÂê¶Â∑≤ÂÆåÊàê
        if check_latents_exist "$OUT_DIR"; then
            echo "‚úÖ [Skip] $subset is marked done or populated."
            continue
        fi

        tar_file="${subset}.tar.gz"
        # 1. ‰∏ãËΩΩ
        if [ ! -d "$subset" ]; then
            if [ -f "$tar_file" ]; then
                echo "üì¶ Found tarball '$tar_file', extracting..."
                tar -xzf "$tar_file" --strip-components=1 && rm "$tar_file"
            else
                echo "‚¨áÔ∏è  Downloading $subset..."
                fast_download "$BASE_URL/$tar_file" "$tar_file"
                if [ -f "$tar_file" ]; then
                    echo "üì¶ Extracting $subset..."
                    tar -xzf "$tar_file" --strip-components=1 && rm "$tar_file"
                fi
            fi
        fi

        # 2. Â§ÑÁêÜ
        if [ -d "$subset" ]; then
            echo "‚öôÔ∏è  Processing $subset -> Latents..."
            $PYTHON_BIN "$BASE_DIR/preprocess/process_dataset.py" \
                --dataset_name "librispeech" --in_dir "$subset" --out_dir "$OUT_DIR" --vae_ckpt "$VAE_CKPT" --workers_per_gpu 4
            
            # [ÂÖ≥ÈîÆ] Â§ÑÁêÜÊàêÂäüÂêéÔºåÁîüÊàê .done Ê†áËÆ∞
            if [ $? -eq 0 ]; then
                touch "$OUT_DIR/.done"
                echo "‚ú® Marked $subset as done."
            fi
        fi
    done
    echo "‚úÖ [LibriSpeech] Finished."
    echo ""
}

# --- LibriTTS-R ---
run_libritts() {
    echo "========================================================"
    echo "üîµ [LibriTTS-R] Checking Pipeline..."
    echo "========================================================"
    
    declare -A MAP=(
        ["train-clean-100"]="train_clean_100" ["train-clean-360"]="train_clean_360"
        ["train-other-500"]="train_other_500" ["dev-clean"]="dev_clean" ["test-clean"]="test_clean"
    )
    declare -A SPLIT_MAP=(
        ["train-clean-100"]="train" ["train-clean-360"]="train" ["train-other-500"]="train"
        ["dev-clean"]="dev" ["test-clean"]="test"
    )
    BASE_URL="https://www.openslr.org/resources/141"
    WORK_DIR="$RAW_ROOT/LibriTTS_R"
    mkdir -p "$WORK_DIR"; cd "$WORK_DIR" || return

    for subset in "${!MAP[@]}"; do
        dl_name=${MAP[$subset]}
        tar_file="${dl_name}.tar.gz"
        split=${SPLIT_MAP[$subset]}
        OUT_DIR="$LATENT_ROOT/$split/LibriTTS_R/$subset"

        # [Âä†ÈÄü] Ê£ÄÊü•ÊòØÂê¶Â∑≤ÂÆåÊàê
        if check_latents_exist "$OUT_DIR"; then
            echo "‚úÖ [Skip] $subset is marked done or populated."
            continue
        fi

        # 1. ‰∏ãËΩΩ
        if [ ! -d "$subset" ]; then
            if [ -d "$dl_name" ]; then mv "$dl_name" "$subset"; 
            elif [ -f "$tar_file" ]; then
                echo "üì¶ Found tarball '$tar_file', extracting..."
                tar -xzf "$tar_file" --strip-components=1 && rm "$tar_file"
                if [ -d "$dl_name" ] && [ "$dl_name" != "$subset" ]; then mv "$dl_name" "$subset"; fi
            else
                echo "‚¨áÔ∏è  Downloading $subset..."
                fast_download "$BASE_URL/$tar_file" "$tar_file"
                if [ -f "$tar_file" ]; then
                    echo "üì¶ Extracting $subset..."
                    tar -xzf "$tar_file" --strip-components=1 && rm "$tar_file"
                    if [ -d "$dl_name" ] && [ "$dl_name" != "$subset" ]; then mv "$dl_name" "$subset"; fi
                fi
            fi
        fi

        # 2. Â§ÑÁêÜ
        if [ -d "$subset" ]; then
            echo "‚öôÔ∏è  Processing $subset -> Latents..."
            $PYTHON_BIN "$BASE_DIR/preprocess/process_dataset.py" \
                --dataset_name "libritts" --in_dir "$subset" --out_dir "$OUT_DIR" --vae_ckpt "$VAE_CKPT" --workers_per_gpu 4
            
            # [ÂÖ≥ÈîÆ] Ê†áËÆ∞ÂÆåÊàê
            if [ $? -eq 0 ]; then
                touch "$OUT_DIR/.done"
                echo "‚ú® Marked $subset as done."
            fi
        fi
    done
    echo "‚úÖ [LibriTTS-R] Finished."
    echo ""
}

# --- Common Voice ---
run_commonvoice() {
    echo "========================================================"
    echo "üü£ [CommonVoice] Checking Pipeline..."
    echo "========================================================"
    
    CV_OUT="$LATENT_ROOT/train/CommonVoice"
    if check_latents_exist "$CV_OUT"; then
        echo "‚úÖ [Skip] CommonVoice is marked done or populated."
        return
    fi

    WORK_DIR="$RAW_ROOT/CommonVoice"
    mkdir -p "$WORK_DIR"; cd "$WORK_DIR" || return
    CV_TAR="common_voice_en.tar.gz"

    if [ ! -d "clips" ] || [ ! -f "train.tsv" ]; then
        if [ ! -f "$CV_TAR" ]; then
            echo "üîç Resolving real download URL via Python..."
            
            # 1. Ë∞ÉÁî® Python ËÑöÊú¨Ëé∑ÂèñÁúüÂÆûÈìæÊé•
            # Á°Æ‰øù get_cv_link.py ÈáåÁöÑ Token ÊòØÊúÄÊñ∞ÁöÑÔºÅ
            REAL_URL=$($PYTHON_BIN "$BASE_DIR/preprocess/get_cv_link.py")
            
            if [ $? -eq 0 ] && [ -n "$REAL_URL" ]; then
                echo "‚úÖ URL Resolved! Target: AWS S3"
                echo "üöÄ [Aria2] Downloading (16 threads)..."
                # S3 ÈìæÊé•Â∏¶Á≠æÂêçÔºå‰∏çÈúÄË¶Å TokenÔºåaria2c ÂèØ‰ª•Ë∑ëÊª°Â∏¶ÂÆΩ
                aria2c -x 16 -s 16 -c -o "$CV_TAR" "$REAL_URL"
            else
                echo "‚ùå Failed to resolve URL. Using reliable Wget fallback..."
                # ÊúÄÂêéÁöÑ‰øùÂ∫ïÔºöÂ¶ÇÊûú Python Ëß£ÊûêÂ§±Ë¥•ÔºåÁî® wget (ËôΩÁÑ∂ÂçïÁ∫øÁ®ã‰ΩÜÊûÅÂÖ∂Á®≥ÂÆö)
                # wget ËÉΩÊ≠£Á°ÆÂ§ÑÁêÜ Auth Â§¥ÂíåÈáçÂÆöÂêë
                wget -c --content-disposition --header="Authorization: Bearer $CV_API_KEY" \
                     "https://datacollective.mozillafoundation.org/api/datasets/cmj8u3p1w0075nxxbe8bedl00/download/$CV_DOWNLOAD_TOKEN" \
                     -O "$CV_TAR"
            fi
        fi

        # 2. Ê†°È™å‰∏éËß£Âéã
        if [ -f "$CV_TAR" ]; then
            echo "üì¶ Verifying archive..."
            if ! gzip -t "$CV_TAR" &>/dev/null; then
                echo "‚ùå Error: Invalid gzip file. Deleting..."
                rm "$CV_TAR"
            else
                echo "üì¶ Extracting..."
                tar -xzf "$CV_TAR"
                FOUND_CLIPS=$(find . -maxdepth 3 -type d -name "clips" | head -n 1)
                if [ -n "$FOUND_CLIPS" ]; then
                    PARENT_DIR=$(dirname "$FOUND_CLIPS")
                    if [ "$PARENT_DIR" != "." ]; then mv "$PARENT_DIR"/* .; rmdir "$PARENT_DIR" 2>/dev/null || true; fi
                fi
                rm "$CV_TAR"
            fi
        fi
    fi

    # 3. Â§ÑÁêÜ
    if [ -d "clips" ] && [ -f "train.tsv" ]; then
        echo "‚öôÔ∏è  Processing CommonVoice -> Latents..."
        $PYTHON_BIN "$BASE_DIR/preprocess/process_dataset.py" \
            --dataset_name "commonvoice" --in_dir "clips" --out_dir "$CV_OUT" --vae_ckpt "$VAE_CKPT" --cv_tsv "train.tsv" --workers_per_gpu 8
        if [ $? -eq 0 ]; then touch "$CV_OUT/.done"; echo "‚ú® Marked CommonVoice as done."; fi
    else
        echo "‚ö†Ô∏è  CommonVoice raw data not found."
    fi
    echo "‚úÖ [CommonVoice] Finished."
    echo ""
}

# ==============================================================================
# ‰∏ªÊâßË°åÈÄªËæë
# ==============================================================================

if [ "$DO_PIPELINE" = true ]; then
    echo "üöÄ Starting Pipelines..."
    
    if contains_element "librispeech" "${DATASETS_TO_RUN[@]}"; then run_librispeech; fi
    if contains_element "libritts" "${DATASETS_TO_RUN[@]}"; then run_libritts; fi
    if contains_element "commonvoice" "${DATASETS_TO_RUN[@]}"; then run_commonvoice; fi
    
    echo "üéâ All pipelines finished!"
fi

if [ "$DO_JSONL" = true ]; then
    echo "========================================================"
    echo "üìù [Stage 3] Building JSONL Manifests..."
    echo "========================================================"
    mkdir -p $JSONL_ROOT
    $PYTHON_BIN "$BASE_DIR/preprocess/build_manifest.py" --latent_dir "$LATENT_ROOT/train" --output_file "$JSONL_ROOT/train.jsonl"
    $PYTHON_BIN "$BASE_DIR/preprocess/build_manifest.py" --latent_dir "$LATENT_ROOT/dev" --output_file "$JSONL_ROOT/dev.jsonl"
    $PYTHON_BIN "$BASE_DIR/preprocess/build_manifest.py" --latent_dir "$LATENT_ROOT/test" --output_file "$JSONL_ROOT/test.jsonl"
    echo "‚úÖ JSONL generation complete!"
fi