import os
import sys
import torch
import torchaudio
import soundfile as sf
import argparse
import logging
from rich.console import Console
from rich.table import Table

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.getcwd())

# å¯¼å…¥ä½ çš„æ¨¡å‹å®šä¹‰
from models.modeling_vae import AcousticVAE, AudioVAEConfig
from preprocess.core import MelExtractor

# é…ç½®æ—¥å¿—
logging.basicConfig(level="ERROR") # å±è”½åº•å±‚æ‚ä¹±æ—¥å¿—
console = Console()

def load_vae(ckpt_path, device):
    console.print(f"[bold blue]Loading VAE from: {ckpt_path}[/bold blue]")
    try:
        # å°è¯•ç›´æ¥åŠ è½½
        vae = AcousticVAE.from_pretrained(ckpt_path)
    except Exception as e:
        console.print(f"[yellow]ç›´æ¥åŠ è½½å¤±è´¥ï¼Œå°è¯•åŠ è½½ state_dict: {e}[/yellow]")
        config = AudioVAEConfig() # ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œå¦‚æœä½ çš„é…ç½®æ”¹è¿‡ï¼Œè¿™é‡Œå¯èƒ½éœ€è¦è°ƒæ•´
        vae = AcousticVAE(config)
        state_dict = torch.load(os.path.join(ckpt_path, "pytorch_model.bin"), map_location="cpu")
        vae.load_state_dict(state_dict, strict=False)
    
    vae.to(device).eval()
    return vae

def load_vocoder(device):
    console.print("[bold blue]Loading HiFi-GAN Vocoder...[/bold blue]")
    from speechbrain.inference.vocoders import HIFIGAN
    hifi = HIFIGAN.from_hparams(
        source="speechbrain/tts-hifigan-libritts-16kHz",
        savedir="tmp_hifigan",
        run_opts={"device": device}
    )
    return hifi

def run_diagnostic(pt_path, wav_path, vae, vocoder, device):
    console.rule("[bold]å¼€å§‹è¯Šæ–­[/bold]")
    
    # 1. åŠ è½½ç¡¬ç›˜ä¸Šçš„ .pt æ–‡ä»¶ (Old Latent)
    console.print(f"ğŸ“‚ è¯»å– PT æ–‡ä»¶: {pt_path}")
    payload = torch.load(pt_path, map_location="cpu")
    # å…¼å®¹å¤„ç†ï¼šæœ‰äº› pt æ˜¯ tensorï¼Œæœ‰äº›æ˜¯ dict
    latent_disk = payload.get("latent", payload) if isinstance(payload, dict) else payload
    
    # ç»´åº¦è°ƒæ•´ [C, T] -> [1, C, T]
    if latent_disk.dim() == 2: 
        latent_disk = latent_disk.unsqueeze(0)
    
    latent_disk = latent_disk.to(device).float()
    
    # 2. è§£ç ç¡¬ç›˜ Latent (è¿˜åŸå£°éŸ³)
    with torch.no_grad():
        mel_disk = vae.decode(latent_disk)
        wav_disk = vocoder.decode_batch(mel_disk).cpu().squeeze()
        
    path_disk = "debug_output_disk_latent.wav"
    sf.write(path_disk, wav_disk.numpy(), 16000)
    console.print(f"ğŸ’¾ [Old] ç¡¬ç›˜Latentè§£ç ä¿å­˜ä¸º: [bold red]{path_disk}[/bold red] (å¬å¬è¿™ä¸ªï¼Œå¦‚æœå…¨æ˜¯å™ªéŸ³ï¼Œè¯´æ˜ptå¤±æ•ˆ)")

    # 3. ç°åœºå¤„ç† Wav (å¦‚æœæä¾›äº†)
    if wav_path and os.path.exists(wav_path):
        console.print(f"ğŸµ è¯»å–åŸå§‹ WAV: {wav_path}")
        
        # æ¨¡æ‹Ÿé¢„å¤„ç†é€»è¾‘
        wav, sr = torchaudio.load(wav_path)
        if sr != 16000: wav = torchaudio.transforms.Resample(sr, 16000)(wav)
        # å…³é”®ï¼šå½’ä¸€åŒ– (å’Œä½  preprocess/core.py ä¿æŒä¸€è‡´)
        wav = wav / (torch.max(torch.abs(wav)) + 1e-8) * 0.95
        wav = wav.to(device)
        
        # æå– Mel
        mel_extractor = MelExtractor().to(device)
        with torch.no_grad():
            mel_gt = mel_extractor(wav)
            
            # ç°åœºç¼–ç  (Fresh Latent)
            # æ³¨æ„ï¼šä½ çš„æ¨¡å‹è¿”å› (mu, logvar)
            mu, logvar = vae.encode(mel_gt)
            latent_fresh = mu # åœ¨ eval æ¨¡å¼ä¸‹é€šå¸¸ä½¿ç”¨å‡å€¼
            
            # ç°åœºè§£ç 
            mel_fresh = vae.decode(latent_fresh)
            wav_fresh = vocoder.decode_batch(mel_fresh).cpu().squeeze()
            
        path_fresh = "debug_output_fresh_encode.wav"
        sf.write(path_fresh, wav_fresh.numpy(), 16000)
        console.print(f"ğŸ’¾ [New] ç°åœºé‡æ–°ç¼–ç ä¿å­˜ä¸º: [bold green]{path_fresh}[/bold green] (å¬å¬è¿™ä¸ªï¼Œè¿™ä»£è¡¨VAEçš„çœŸå®æ°´å¹³)")
        
        # 4. æ•°å€¼å¯¹æ¯” (çœŸç›¸æ—¶åˆ»)
        # ç¡®ä¿ç»´åº¦å¯¹é½ (æœ‰æ—¶å€™ pt é‡Œå¯èƒ½æ˜¯è½¬ç½®è¿‡çš„)
        if latent_disk.shape != latent_fresh.shape:
             # å°è¯•è½¬ç½®åŒ¹é…
             if latent_disk.shape[-1] == latent_fresh.shape[1]:
                 latent_disk = latent_disk.transpose(1, 2)
        
        # æˆªå–ç›¸åŒé•¿åº¦å¯¹æ¯”
        min_len = min(latent_disk.shape[-1], latent_fresh.shape[-1])
        diff = torch.abs(latent_disk[..., :min_len] - latent_fresh[..., :min_len]).mean().item()
        
        table = Table(title="Latent æ•°å€¼å¯¹æ¯”")
        table.add_column("Metric", style="cyan")
        table.add_column("Value", style="magenta")
        table.add_row("ç¡¬ç›˜ Latent å‡å€¼", f"{latent_disk.mean().item():.4f}")
        table.add_row("ç°åœº Latent å‡å€¼", f"{latent_fresh.mean().item():.4f}")
        table.add_row("ä¸¤è€…å¹³å‡å·®å¼‚ (L1)", f"{diff:.4f}")
        
        console.print(table)
        
        if diff > 0.5:
            console.print("[bold red]âš ï¸ è­¦å‘Šï¼šå·®å¼‚å·¨å¤§ï¼[/bold red]")
            console.print("è¿™è¯´æ˜ã€ç¡¬ç›˜é‡Œçš„ .ptã€‘å’Œã€å½“å‰ VAE ç®—å‡ºæ¥çš„ã€‘å®Œå…¨ä¸æ˜¯ä¸€å›äº‹ã€‚")
            console.print("å¯èƒ½åŸå› ï¼š")
            console.print("1. ä½ è™½ç„¶ç”¨äº†'è€VAE'ï¼Œä½†å¯èƒ½æ˜¯ä¸å°å¿ƒç”¨äº†ä¸åŒçš„ checkpoint (æ¯”å¦‚ step 5k å’Œ step 10k)ã€‚")
            console.print("2. é¢„å¤„ç†å‚æ•°å˜äº† (æ¯”å¦‚ä¹‹å‰æ˜¯ Power 1.0, ç°åœ¨çš„ core.py æ˜¯ Power 2.0)ã€‚")
        else:
            console.print("[bold green]âœ… å·®å¼‚å¾ˆå°ï¼ŒLatent æ˜¯ä¸€è‡´çš„ã€‚[/bold green]")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--pt", type=str, required=True, help="Path to a .pt file")
    parser.add_argument("--wav", type=str, required=True, help="Path to the corresponding .wav file")
    parser.add_argument("--vae", type=str, required=True, help="Path to VAE checkpoint folder")
    args = parser.parse_args()
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    vae = load_vae(args.vae, device)
    vocoder = load_vocoder(device)
    
    run_diagnostic(args.pt, args.wav, vae, vocoder, device)