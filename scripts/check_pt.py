import os
import sys
import torch
import torchaudio
import soundfile as sf
import argparse
import logging
import numpy as np
from rich.console import Console
from rich.table import Table
from rich.panel import Panel

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.getcwd())

# å¯¼å…¥ä½ çš„æ¨¡å‹å®šä¹‰
try:
    from models.modeling_vae import AcousticVAE, AudioVAEConfig
    from preprocess.core import MelExtractor
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥æ¨¡å‹ï¼Œè¯·ç¡®ä¿ä½ åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬ (ä¾‹å¦‚: python scripts/diagnose_full.py ...)")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(level="ERROR") # å±è”½åº•å±‚æ‚ä¹±æ—¥å¿—
console = Console()

# ==============================================================================
# 1. æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
# ==============================================================================

def analyze_distribution(latent_tensor, name="Latent"):
    """
    ç§»æ¤è‡ª scripts/check_latents.py çš„æ ¸å¿ƒç»Ÿè®¡é€»è¾‘
    """
    # ç¡®ä¿æ˜¯ float å¹¶ä¸”åœ¨ CPU ä¸Šè®¡ç®—ç»Ÿè®¡é‡
    data = latent_tensor.detach().cpu().float()
    
    # 1. åŸºç¡€æ£€æŸ¥
    has_nan = torch.isnan(data).any().item()
    has_inf = torch.isinf(data).any().item()
    
    l_min = data.min().item()
    l_max = data.max().item()
    l_mean = data.mean().item()
    l_std = data.std().item()
    
    # 2. æ‰“å°è¡¨æ ¼
    table = Table(title=f"ğŸ“Š åˆ†å¸ƒç»Ÿè®¡: {name}", border_style="cyan")
    table.add_column("Metric", style="bold white")
    table.add_column("Value", style="bold yellow")
    table.add_column("Health Check", style="bold")

    # NaN / Inf Check
    status_nan = "[bold red]FAIL[/bold red]" if has_nan else "[green]PASS[/green]"
    status_inf = "[bold red]FAIL[/bold red]" if has_inf else "[green]PASS[/green]"
    table.add_row("Contains NaN", str(has_nan), status_nan)
    table.add_row("Contains Inf", str(has_inf), status_inf)
    
    # Stats Check
    table.add_row("Min", f"{l_min:.4f}", "")
    table.add_row("Max", f"{l_max:.4f}", "")
    
    # Mean Check (Should be close to 0)
    mean_status = "[green]OK[/green]" if abs(l_mean) < 0.5 else "[yellow]SHIFTED[/yellow]"
    table.add_row("Mean", f"{l_mean:.4f}", mean_status)
    
    # Std Check (Should be close to 1, or at least > 0.1)
    if l_std < 0.1: std_status = "[bold red]COLLAPSED (Too Small)[/bold red]"
    elif l_std > 5.0: std_status = "[bold red]EXPLODED (Too Large)[/bold red]"
    else: std_status = "[green]OK[/green]"
    table.add_row("Std Dev", f"{l_std:.4f}", std_status)
    
    console.print(table)
    
    # 3. è¯Šæ–­å»ºè®®
    if l_std < 0.5:
        scale_factor = 1.0 / (l_std + 1e-8)
        console.print(f"[yellow]ğŸ’¡ å»ºè®®: æ–¹å·®è¿‡å°ã€‚å¦‚æœè¿™æ˜¯ Flow Matching çš„ç›®æ ‡ï¼Œå»ºè®®è®­ç»ƒæ—¶ä¹˜ä»¥ {scale_factor:.2f}[/yellow]")
    elif l_std > 2.0:
        scale_factor = 1.0 / (l_std + 1e-8)
        console.print(f"[yellow]ğŸ’¡ å»ºè®®: æ–¹å·®è¿‡å¤§ã€‚å»ºè®®è®­ç»ƒæ—¶ä¹˜ä»¥ {scale_factor:.2f}[/yellow]")
    
    return l_mean, l_std

def load_vae(ckpt_path, device):
    console.print(f"[bold blue]Loading VAE from: {ckpt_path}[/bold blue]")
    try:
        # å°è¯•ç›´æ¥åŠ è½½
        vae = AcousticVAE.from_pretrained(ckpt_path)
    except Exception as e:
        console.print(f"[yellow]ç›´æ¥åŠ è½½å¤±è´¥ï¼Œå°è¯•åŠ è½½ state_dict: {e}[/yellow]")
        config = AudioVAEConfig() # ä½¿ç”¨é»˜è®¤é…ç½®
        vae = AcousticVAE(config)
        
        # å…¼å®¹ pytorch_model.bin æˆ– model.safetensors
        bin_path = os.path.join(ckpt_path, "pytorch_model.bin")
        if not os.path.exists(bin_path):
            # ç®€å•å°è¯•é€’å½’æŸ¥æ‰¾
            import glob
            files = glob.glob(os.path.join(ckpt_path, "**/*.bin"), recursive=True)
            if files: bin_path = files[0]
            
        if os.path.exists(bin_path):
            state_dict = torch.load(bin_path, map_location="cpu")
            vae.load_state_dict(state_dict, strict=False)
        else:
            console.print("[bold red]âŒ æ‰¾ä¸åˆ° VAE æƒé‡æ–‡ä»¶ï¼[/bold red]")
            sys.exit(1)
    
    vae.to(device).eval()
    return vae

def load_vocoder(device):
    console.print("[bold blue]Loading HiFi-GAN Vocoder...[/bold blue]")
    try:
        from speechbrain.inference.vocoders import HIFIGAN
        hifi = HIFIGAN.from_hparams(
            source="speechbrain/tts-hifigan-libritts-16kHz",
            savedir="tmp_hifigan",
            run_opts={"device": device}
        )
        return hifi
    except ImportError:
        console.print("[red]âŒ éœ€è¦å®‰è£… speechbrain: pip install speechbrain[/red]")
        sys.exit(1)

# ==============================================================================
# 2. ä¸»æµç¨‹
# ==============================================================================

def run_diagnostic(pt_path, wav_path, vae, vocoder, device):
    console.rule("[bold]å¼€å§‹å…¨èƒ½è¯Šæ–­[/bold]")
    
    # --- é˜¶æ®µ 1: ç¡¬ç›˜æ–‡ä»¶ (.pt) åˆ†æ ---
    console.print(Panel(f"ğŸ“‚ é˜¶æ®µ 1: åˆ†æç¡¬ç›˜æ–‡ä»¶\n{pt_path}", style="bold cyan"))
    
    if not os.path.exists(pt_path):
        console.print("[red]âŒ .pt æ–‡ä»¶ä¸å­˜åœ¨[/red]")
        return

    payload = torch.load(pt_path, map_location="cpu")
    # å…¼å®¹å¤„ç†ï¼šæœ‰äº› pt æ˜¯ tensorï¼Œæœ‰äº›æ˜¯ dict
    if isinstance(payload, dict):
        latent_disk = payload.get("latent", payload.get("mel", None))
        if latent_disk is None:
            console.print(f"[red]âŒ å­—å…¸ä¸­æ‰¾ä¸åˆ° 'latent' æˆ– 'mel' é”®ã€‚Keys: {list(payload.keys())}[/red]")
            return
    else:
        latent_disk = payload
    
    # ç»´åº¦è°ƒæ•´ [C, T] -> [1, C, T]
    if latent_disk.dim() == 2: 
        latent_disk = latent_disk.unsqueeze(0)
    
    latent_disk = latent_disk.to(device).float()
    
    # [æ–°å¢åŠŸèƒ½] ç»Ÿè®¡åˆ†å¸ƒ
    analyze_distribution(latent_disk, "ç¡¬ç›˜ Latent (.pt)")
    
    # è§£ç ç¡¬ç›˜ Latent (è¿˜åŸå£°éŸ³)
    console.print("ğŸ”„ æ­£åœ¨è§£ç ç¡¬ç›˜ Latent...")
    with torch.no_grad():
        mel_disk = vae.decode(latent_disk)
        # å…¼å®¹ HiFi-GAN çš„ Log é¢„å¤„ç†
        # å‡è®¾ VAE è¾“å‡ºæ˜¯ Log Mel (ln), HiFi-GAN éœ€è¦ Log10 Mel
        # å¦‚æœä½ çš„ VAE è¾“å‡ºæ˜¯ Linearï¼Œè¿™é‡Œå¯èƒ½ä¼šç‚¸ï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬è¦æµ‹çš„
        mel_for_vocoder = mel_disk * 0.43429
        wav_disk = vocoder.decode_batch(mel_for_vocoder).cpu().squeeze()
        
    path_disk = "debug_output_disk_latent.wav"
    sf.write(path_disk, wav_disk.numpy(), 16000)
    console.print(f"ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: [bold red]{path_disk}[/bold red] (å¬å¬æ˜¯å¦æ­£å¸¸)")


    # --- é˜¶æ®µ 2: åŸå§‹ Wav å¯¹æ¯”åˆ†æ ---
    if wav_path and os.path.exists(wav_path):
        console.print(Panel(f"ğŸµ é˜¶æ®µ 2: å¯¹æ¯”åŸå§‹ Wav\n{wav_path}", style="bold magenta"))
        
        # æ¨¡æ‹Ÿé¢„å¤„ç†é€»è¾‘ (ä¸ preprocess/core.py ä¿æŒä¸€è‡´)
        wav, sr = torchaudio.load(wav_path)
        if sr != 16000: wav = torchaudio.transforms.Resample(sr, 16000)(wav)
        # å…³é”®ï¼šå½’ä¸€åŒ–
        wav = wav / (torch.max(torch.abs(wav)) + 1e-8) * 0.95
        wav = wav.to(device)
        if wav.dim() == 1: wav = wav.unsqueeze(0)
        
        # æå– Mel
        mel_extractor = MelExtractor().to(device)
        with torch.no_grad():
            mel_gt = mel_extractor(wav)
            
            # ç°åœºç¼–ç  (Fresh Latent)
            mu, logvar = vae.encode(mel_gt)
            latent_fresh = mu # åœ¨ eval æ¨¡å¼ä¸‹é€šå¸¸ä½¿ç”¨å‡å€¼
            
            # [æ–°å¢åŠŸèƒ½] ç»Ÿè®¡ç°åœºåˆ†å¸ƒ
            analyze_distribution(latent_fresh, "ç°åœºç¼–ç  Latent (Fresh)")
            
            # ç°åœºè§£ç 
            mel_fresh = vae.decode(latent_fresh)
            mel_fresh_vocoder = mel_fresh * 0.43429
            wav_fresh = vocoder.decode_batch(mel_fresh_vocoder).cpu().squeeze()
            
        path_fresh = "debug_output_fresh_encode.wav"
        sf.write(path_fresh, wav_fresh.numpy(), 16000)
        console.print(f"ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: [bold green]{path_fresh}[/bold green] (ä»£è¡¨å½“å‰ VAE çš„èƒ½åŠ›ä¸Šé™)")
        
        # --- é˜¶æ®µ 3: æœ€ç»ˆå¯¹æ¯” ---
        console.print(Panel("ğŸ” é˜¶æ®µ 3: æ–°æ—§ä¸€è‡´æ€§æ£€æŸ¥", style="bold white"))
        
        # ç»´åº¦å¯¹é½
        t_disk = latent_disk
        t_fresh = latent_fresh
        
        if t_disk.shape != t_fresh.shape:
             console.print(f"[yellow]âš ï¸ å½¢çŠ¶ä¸åŒ¹é…: Disk{t_disk.shape} vs Fresh{t_fresh.shape}[/yellow]")
             # å°è¯•è½¬ç½®
             if t_disk.shape[-1] == t_fresh.shape[1]:
                 t_disk = t_disk.transpose(1, 2)
                 console.print("   -> å·²è½¬ç½® Disk Latent ä»¥åŒ¹é…")
        
        # æˆªå–ç›¸åŒé•¿åº¦
        min_len = min(t_disk.shape[-1], t_fresh.shape[-1])
        t_disk = t_disk[..., :min_len]
        t_fresh = t_fresh[..., :min_len]
        
        diff = torch.abs(t_disk - t_fresh).mean().item()
        
        table = Table(title="ä¸€è‡´æ€§å¯¹æ¯”")
        table.add_column("Metric")
        table.add_column("Result")
        table.add_row("å¹³å‡ L1 å·®å¼‚", f"{diff:.4f}")
        
        if diff > 0.5:
            res_style = "[bold red]FAIL[/bold red]"
            msg = "å·®å¼‚å·¨å¤§ï¼é¢„å¤„ç†æµç¨‹æˆ– VAE ç‰ˆæœ¬ä¸ä¸€è‡´ï¼"
        elif diff > 0.1:
            res_style = "[yellow]WARNING[/yellow]"
            msg = "å­˜åœ¨æ˜æ˜¾å·®å¼‚ï¼Œå¯èƒ½æ˜¯ Padding æˆ– å½’ä¸€åŒ–å‚æ•°å¾®è°ƒå¯¼è‡´ã€‚"
        else:
            res_style = "[bold green]PASS[/bold green]"
            msg = "ä¸¤è€…åŸºæœ¬ä¸€è‡´ã€‚"
            
        table.add_row("ç»“è®º", res_style)
        console.print(table)
        console.print(msg)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Audio-CALM VAE & Data Diagnostic Tool")
    parser.add_argument("--pt", type=str, required=True, help="Path to a .pt file (latent)")
    parser.add_argument("--wav", type=str, required=True, help="Path to the corresponding source .wav file")
    parser.add_argument("--vae", type=str, required=True, help="Path to VAE checkpoint folder")
    args = parser.parse_args()
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    vae = load_vae(args.vae, device)
    vocoder = load_vocoder(device)
    
    run_diagnostic(args.pt, args.wav, vae, vocoder, device)
    
# python ./scripts/check_pt.py --pt "/data0/determined/users/andywu/Audio-CALM-v2/data/latents/dev/LibriTTS_R/dev-clean/84/121123/84_121123_000008_000001.pt" --wav "/data0/determined/users/andywu/Audio-CALM-v2/data/raw/LibriTTS_R/dev/dev-clean/84/121123/84_121123_000008_000001.wav" --vae "/data0/determined/users/andywu/Audio-CALM-v2/outputs/checkpoints/vae_4x_64_5e-4/checkpoint-8700"